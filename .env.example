# =============================================================================
# Dudoxx Whisper STT - Environment Configuration
# =============================================================================
# Copy this file to .env and update with your values
# =============================================================================

# -----------------------------------------------------------------------------
# HuggingFace Configuration (Required for Diarization)
# -----------------------------------------------------------------------------
# Get your token from: https://huggingface.co/settings/tokens
# Required for pyannote models used in speaker diarization
HF_TOKEN=your_huggingface_token_here

# -----------------------------------------------------------------------------
# Server Configuration
# -----------------------------------------------------------------------------
# Port for the STT server
STT_PORT=4300

# Host to bind the server to
STT_HOST=localhost

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# -----------------------------------------------------------------------------
# Whisper Model Configuration
# -----------------------------------------------------------------------------
# Model size: tiny, base, small, medium, large-v2, large-v3, large-v3-turbo
# Larger models = better quality but slower and more memory
# Recommended: large-v3-turbo (best balance of speed and quality)
WHISPER_MODEL=large-v3-turbo

# Backend: auto, mlx-whisper, faster-whisper, whisper, openai-api
# mlx-whisper is optimized for Apple Silicon (M1/M2/M3)
# faster-whisper is optimized for NVIDIA GPUs
WHISPER_BACKEND=mlx-whisper

# Default language: auto (for detection) or language code (en, fr, de, etc.)
DEFAULT_LANGUAGE=auto

# -----------------------------------------------------------------------------
# Diarization Configuration (Speaker Identification)
# -----------------------------------------------------------------------------
# Enable speaker diarization
DIARIZATION_ENABLED=false

# Diarization backend: sortformer (NVIDIA GPU) or diart (CPU/GPU with pyannote)
# sortformer: Best quality, requires NVIDIA GPU and NeMo toolkit
# diart: Works on CPU/GPU, requires HuggingFace token for pyannote models
DIARIZATION_BACKEND=diart

# Pyannote segmentation model (for diart backend)
SEGMENTATION_MODEL=pyannote/segmentation-3.0

# Pyannote embedding model (for diart backend)
EMBEDDING_MODEL=pyannote/embedding

# -----------------------------------------------------------------------------
# Voice Activity Detection (VAD)
# -----------------------------------------------------------------------------
# Enable VAD to filter out silence
VAD_ENABLED=true

# VAC (Voice Activity Controller) for chunking
VAC_ENABLED=true
VAC_CHUNK_SIZE=0.04

# -----------------------------------------------------------------------------
# Streaming Configuration
# -----------------------------------------------------------------------------
# Backend policy: simulstreaming (AlignAtt) or localagreement
BACKEND_POLICY=simulstreaming

# Minimum chunk size in seconds
MIN_CHUNK_SIZE=0.1

# Buffer trimming: sentence or segment
BUFFER_TRIMMING=segment

# Buffer trimming threshold in seconds
BUFFER_TRIMMING_SEC=15

# -----------------------------------------------------------------------------
# Translation Configuration (Optional)
# -----------------------------------------------------------------------------
# Target language for translation (leave empty to disable)
TARGET_LANGUAGE=

# Direct English translation (uses Whisper's built-in translation)
DIRECT_ENGLISH_TRANSLATION=false

# NLLB translation backend: transformers or ctranslate2
NLLB_BACKEND=transformers

# NLLB model size: 600M or 1.3B
NLLB_SIZE=600M

# -----------------------------------------------------------------------------
# Advanced Configuration
# -----------------------------------------------------------------------------
# Frame threshold for attention-guided decoding
FRAME_THRESHOLD=25

# Maximum audio buffer length in seconds
AUDIO_MAX_LEN=30.0

# Minimum audio length before processing in seconds
AUDIO_MIN_LEN=0.0

# Number of beams for beam search (1 = greedy decoding)
BEAMS=1

# Decoder type: greedy or beam
DECODER_TYPE=greedy

# Initial prompt for the model (helps with domain-specific vocabulary)
INIT_PROMPT=

# Static init prompt (persists across segments)
STATIC_INIT_PROMPT=

# Model cache directory (optional, for custom model storage)
MODEL_CACHE_DIR=

# -----------------------------------------------------------------------------
# SSL Configuration (for HTTPS)
# -----------------------------------------------------------------------------
SSL_CERTFILE=
SSL_KEYFILE=

# Forwarded allow IPs for reverse proxy
FORWARDED_ALLOW_IPS=

# -----------------------------------------------------------------------------
# Audio Input Configuration
# -----------------------------------------------------------------------------
# Use raw PCM input (AudioWorklet) instead of MediaRecorder
PCM_INPUT=false
